{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving $l_0$ compressed sensing on random linear system with various classical and quantum solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using classical solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_wN0DaO5uRMs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/Users/po-jenwang/.cache/uv/archive-v0/vqXlQ0hQs2p0b6M4qeL8e` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m91 packages\u001b[0m \u001b[2min 381ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m6 packages\u001b[0m \u001b[2min 1.20s\u001b[0m\u001b[0m                                             \n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 198ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 51ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclarabel\u001b[0m\u001b[2m==0.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcvxopt\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcvxpy\u001b[0m\u001b[2m==1.6.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgurobipy\u001b[0m\u001b[2m==12.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mosqp\u001b[0m\u001b[2m==1.0.4\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyscipopt\u001b[0m\u001b[2m==5.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscs\u001b[0m\u001b[2m==3.2.7.post2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add \"cvxpy[CVXOPT,GLPK,GUROBI,SCIP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z0qhPLedtXhT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cvxpy as cp\n",
    "\n",
    "def solve_l0_cvxpy_miqp(\n",
    "        A_matrix,       # Sensing matrix (M, N)\n",
    "        y_vector,       # Measurement vector (M,)\n",
    "        lambda_val,     # Sparsity regularization parameter for L0 norm\n",
    "        N_signal,       # Number of signal components\n",
    "        M_measure,      # Number of measurements\n",
    "        big_M_value=None, # Big-M for constraints s_i vs x_i\n",
    "        solver=None,    # CVXPY solver (e.g., cp.GUROBI, cp.MOSEK, cp.ECOS_BB)\n",
    "        verbose_solver=False,\n",
    "        verbose_script=True):\n",
    "    \"\"\"\n",
    "    Solves L0-regularized problem: min 0.5 ||A s - y||^2 + lambda ||s||_0\n",
    "    as a Mixed-Integer Quadratic Program (MIQP) using CVXPY.\n",
    "\n",
    "    Returns s_recovered (signal values), x_recovered (binary support).`\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Define CVXPY Variables ---\n",
    "    s_vars = cp.Variable(N_signal, name=\"s\")  # Continuous signal values\n",
    "    x_vars = cp.Variable(N_signal, boolean=True, name=\"x\") # Binary support variables\n",
    "\n",
    "    # --- Estimate Big-M if not provided ---\n",
    "    # Should be an upper bound on any |s_i|\n",
    "    if big_M_value is None:\n",
    "        try:\n",
    "            # A rough estimate based on a simple least squares solution\n",
    "            s_lstsq_temp = np.linalg.lstsq(A_matrix, y_vector, rcond=None)[0]\n",
    "            big_M_value = 5 * np.max(np.abs(s_lstsq_temp)) if np.any(s_lstsq_temp) else 100.0\n",
    "        except np.linalg.LinAlgError: # Fallback if lstsq fails (e.g. M < N, underdetermined)\n",
    "             big_M_value = 100.0 # Default if lstsq fails\n",
    "        if big_M_value < 1.0 : big_M_value = 10.0 # Ensure it's reasonably large\n",
    "        if verbose_script: print(f\"  CVXPY MIQP: Estimated Big-M = {big_M_value:.2f}\")\n",
    "\n",
    "    if np.isinf(big_M_value) or np.isnan(big_M_value) or big_M_value <=0 :\n",
    "        if verbose_script: print(f\"  CVXPY MIQP: Invalid Big-M {big_M_value}, defaulting to 100.0\")\n",
    "        big_M_value = 100.0\n",
    "\n",
    "\n",
    "    # --- Define Objective Function ---\n",
    "    # 0.5 * ||A s - y||^2_2 + lambda * sum(x_i)\n",
    "    # CVXPY's sum_squares is ||.||^2, so we need 0.5 factor.\n",
    "    l2_term = 0.5 * cp.sum_squares(A_matrix @ s_vars - y_vector)\n",
    "    l0_term = lambda_val * cp.sum(x_vars)\n",
    "    objective = cp.Minimize(l2_term + l0_term)\n",
    "\n",
    "    # --- Define Constraints (Big-M formulation) ---\n",
    "    # -M x_i <= s_i <= M x_i\n",
    "    constraints = []\n",
    "    for i in range(N_signal):\n",
    "        constraints.append(s_vars[i] <= big_M_value * x_vars[i])\n",
    "        constraints.append(s_vars[i] >= -big_M_value * x_vars[i])\n",
    "        # constraints.append(cp.abs(s_vars[i]) <= big_M_value * x_vars[i]) # Alternative for some solvers\n",
    "\n",
    "    # --- Create and Solve Problem ---\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    s_recovered = np.zeros(N_signal)\n",
    "    x_recovered = np.zeros(N_signal)\n",
    "\n",
    "    if verbose_script:\n",
    "        print(f\"  CVXPY MIQP: Solving with N={N_signal}, M={M_measure}, lambda={lambda_val}, BigM={big_M_value:.1f}\")\n",
    "        if solver: print(f\"  Using solver: {solver}\")\n",
    "        else: print(\"  Using default CVXPY MIQP solver (ensure one is installed: GUROBI, MOSEK, CPLEX, CBC, GLPK_MI, ECOS_BB etc.)\")\n",
    "\n",
    "    try:\n",
    "        # Solve the problem\n",
    "        # ECOS_BB is a common open-source mixed-integer SOCP solver that CVXPY can use.\n",
    "        # GLPK_MI can handle MIQPs if the quadratic part is convex (which ours is).\n",
    "        # If commercial solvers like GUROBI or MOSEK are installed, CVXPY will find them.\n",
    "        if solver:\n",
    "            problem.solve(solver=solver, verbose=verbose_solver)\n",
    "        else:\n",
    "            problem.solve(verbose=verbose_solver) # Let CVXPY pick\n",
    "\n",
    "        if problem.status in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:\n",
    "            if verbose_script: print(f\"  CVXPY MIQP: Optimization successful (Status: {problem.status}). Objective value: {problem.value:.4e}\")\n",
    "            s_recovered = s_vars.value\n",
    "            x_recovered = (x_vars.value > 0.5).astype(float) # Ensure binary from boolean var\n",
    "\n",
    "            # It's possible s_vars.value might have small non-zeros where x_vars.value is ~0.\n",
    "            # Enforce s_i = 0 if x_i = 0.\n",
    "            if s_recovered is not None and x_recovered is not None:\n",
    "                 s_recovered[x_recovered < 0.5] = 0.0\n",
    "            else: # Handle cases where solution is None despite OPTIMAL status (rare)\n",
    "                 if verbose_script: print(\"  CVXPY MIQP: Warning - s_vars or x_vars value is None despite optimal status.\")\n",
    "                 s_recovered = np.zeros(N_signal) # Fallback\n",
    "                 x_recovered = np.zeros(N_signal) # Fallback\n",
    "\n",
    "\n",
    "        else:\n",
    "            if verbose_script: print(f\"  CVXPY MIQP: Optimization FAILED. Status: {problem.status}\")\n",
    "            s_recovered = np.zeros(N_signal) # Fallback\n",
    "            x_recovered = np.zeros(N_signal) # Fallback\n",
    "            if s_vars.value is not None : s_recovered = s_vars.value # Use partial if available\n",
    "            if x_vars.value is not None : x_recovered = (x_vars.value > 0.5).astype(float)\n",
    "            s_recovered[x_recovered < 0.5] = 0.0\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose_script: print(f\"  CVXPY MIQP: An error occurred during solve: {e}\")\n",
    "        s_recovered = np.zeros(N_signal) # Fallback\n",
    "        x_recovered = np.zeros(N_signal) # Fallback\n",
    "\n",
    "    return s_recovered, x_recovered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5RoP0GZvSB9",
    "outputId": "86a41ac4-3452-4eff-9ac9-fca90414efa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True sparse signal (s_true) [10 non-zeros]:\n",
      "[-10.1747535   -9.2369111    0.           0.           0.\n",
      "   4.3226711    0.           0.           5.72588681   5.942742\n",
      "   0.          -8.03849336   0.          -7.72407223   0.\n",
      "   0.         -10.73984073   0.           0.           0.\n",
      "   0.           0.          -0.60305369   3.31313741   0.        ]\n",
      "\n",
      "Sensing matrix A shape: (15, 25)\n",
      "Measurement vector y shape: (15,)\n",
      "\n",
      "--- Calling L0 Solver (CVXPY MIQP) ---\n",
      "Installed MIQP-capable solvers: ['CLARABEL', 'CVXOPT', 'GLPK', 'GLPK_MI', 'GUROBI', 'OSQP', 'SCIP', 'SCIPY', 'SCS']\n",
      "  CVXPY MIQP: Estimated Big-M = 31.03\n",
      "  CVXPY MIQP: Solving with N=25, M=15, lambda=0.01, BigM=31.0\n",
      "  Using solver: GUROBI\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "  CVXPY MIQP: Optimization successful (Status: optimal). Objective value: 1.0000e-01\n",
      "\n",
      "CVXPY MIQP Solver finished in 1.31 seconds.\n",
      "\n",
      "True s:              [-10.175  -9.237   0.000   0.000   0.000   4.323   0.000   0.000   5.726\n",
      "   5.943   0.000  -8.038   0.000  -7.724   0.000   0.000 -10.740   0.000\n",
      "   0.000   0.000   0.000   0.000  -0.603   3.313   0.000]\n",
      "Recovered s (CVXPY): [-10.175  -9.237   0.000   0.000   0.000   4.323   0.000   0.000   5.726\n",
      "   5.943   0.000  -8.038   0.000  -7.724   0.000   0.000 -10.740   0.000\n",
      "   0.000   0.000   0.000   0.000  -0.603   3.313   0.000]\n",
      "Recovered x (CVXPY): [1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0.]\n",
      "\n",
      "MSE (s_true vs s_reconstructed): 3.7491e-30\n",
      "MSE (y_true vs A@s_reconstructed): 3.6182e-29\n",
      "True sparsity: 10, Recovered sparsity: 10\n",
      "CVXPY L0 Objective Value (lambda=0.01): 1.0000e-01\n",
      "True support: {0, 1, 5, 8, 9, 11, 13, 16, 22, 23}\n",
      "Recovered support (CVXPY): {0, 1, 5, 8, 9, 11, 13, 16, 22, 23}\n",
      "SUCCESS: Exact support and close values recovery by CVXPY MIQP!\n"
     ]
    }
   ],
   "source": [
    "# --- Main Test Script ---\n",
    "if __name__ == '__main__':\n",
    "    N_signal = 25\n",
    "    M_measurements = 15\n",
    "    sparsity_true = 10\n",
    "    lambda_l0_param = 0.01 # Lambda for the L0 objective\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # 1. Generate a true sparse signal s_true\n",
    "    s_true = np.zeros(N_signal)\n",
    "    non_zero_indices = np.random.choice(N_signal, sparsity_true, replace=False)\n",
    "    # Make true signal values distinct and somewhat large to test Big-M\n",
    "    s_true[non_zero_indices] = (np.random.randn(sparsity_true) * 3) + np.copysign(5, np.random.randn(sparsity_true))\n",
    "    print(f\"True sparse signal (s_true) [{np.sum(s_true!=0)} non-zeros]:\\n{s_true}\")\n",
    "\n",
    "    # 2. Generate a random sensing matrix A\n",
    "    A_sensing_matrix = np.random.randn(M_measurements, N_signal)\n",
    "    # A_sensing_matrix = A_sensing_matrix / np.linalg.norm(A_sensing_matrix, axis=0, keepdims=True)\n",
    "    print(f\"\\nSensing matrix A shape: {A_sensing_matrix.shape}\")\n",
    "\n",
    "    # 3. Compute measurements y\n",
    "    y_measurements = A_sensing_matrix @ s_true\n",
    "    print(f\"Measurement vector y shape: {y_measurements.shape}\")\n",
    "\n",
    "    # --- Call the CVXPY MIQP Solver ---\n",
    "    print(\"\\n--- Calling L0 Solver (CVXPY MIQP) ---\")\n",
    "\n",
    "    # Estimate Big-M based on the true signal's max possible value, or use a generous fixed one\n",
    "    # M_val_heuristic = 1.1 * np.max(np.abs(s_true)) if np.any(s_true) else 100.0\n",
    "    M_val_heuristic = None # Let the solver estimate\n",
    "\n",
    "    # Try to specify a solver if you have one installed that's good for MIQP\n",
    "    # Examples: cp.GUROBI, cp.MOSEK, cp.CPLEX, cp.XPRESS\n",
    "    # Open-source options for MIQP (may need to be installed separately & CVXPY bindings):\n",
    "    # cp.SCIP, cp.HIGHS (HiGHS can do MIQP)\n",
    "    # For general mixed-integer convex programs (incl. MIQP if Q is PSD):\n",
    "    # cp.ECOS_BB (often default for small mixed-integer SOCP/QP)\n",
    "    # cp.GLPK_MI (can sometimes handle MIQP)\n",
    "    # cp.CBC (via cylp - primarily MILP, but can be tried)\n",
    "\n",
    "    # Let's try ECOS_BB which is often bundled with CVXPY's default install\n",
    "    # Or GLPK_MI if available. If you have Gurobi/Mosek, that's best.\n",
    "    # If `solver=None`, CVXPY will try to pick one.\n",
    "\n",
    "    # Check available solvers:\n",
    "    # print(\"Installed MIQP-capable solvers:\", cp.installed_solvers())\n",
    "    # Pick one based on availability. ECOS_BB is a good general one if others aren't present.\n",
    "    # GUROBI, MOSEK, CPLEX are best for MIQP.\n",
    "    # SCIP is a strong open-source option.\n",
    "    # ECOS_BB can handle MIQPs.\n",
    "\n",
    "    available_solvers = cp.installed_solvers()\n",
    "    print(f\"Installed MIQP-capable solvers: {available_solvers}\")\n",
    "    # miqp_solver_to_use = None\n",
    "    # if cp.GUROBI in available_solvers: miqp_solver_to_use = cp.GUROBI\n",
    "    # elif cp.MOSEK in available_solvers: miqp_solver_to_use = cp.MOSEK\n",
    "    # elif cp.CPLEX in available_solvers: miqp_solver_to_use = cp.CPLEX\n",
    "    # elif cp.XPRESS in available_solvers: miqp_solver_to_use = cp.XPRESS\n",
    "    # elif cp.SCIP in available_solvers: miqp_solver_to_use = cp.SCIP # May need to ensure SCIP supports MIQP via CVXPY well\n",
    "    # elif cp.ECOS_BB in available_solvers: miqp_solver_to_use = cp.ECOS_BB\n",
    "    # elif cp.GLPK_MI in available_solvers: miqp_solver_to_use = cp.GLPK_MI\n",
    "\n",
    "    # miqp_solver_to_use = cp.ECOS_BB # Defaulting to ECOS_BB for broader compatibility\n",
    "    # miqp_solver_to_use = cp.GLPK_MI # Try if ECOS_BB fails or is slow\n",
    "\n",
    "    # --- WORKING SOLVERS--------------\n",
    "    # miqp_solver_to_use = cp.SCIP # To let CVXPY choose\n",
    "    miqp_solver_to_use = cp.GUROBI # To let CVXPY choose\n",
    "\n",
    "    start_time = time.time()\n",
    "    s_recovered_cvxpy, x_recovered_cvxpy = solve_l0_cvxpy_miqp(\n",
    "        A_matrix=A_sensing_matrix,\n",
    "        y_vector=y_measurements,\n",
    "        lambda_val=lambda_l0_param,\n",
    "        N_signal=N_signal,\n",
    "        M_measure=M_measurements,\n",
    "        big_M_value=M_val_heuristic,\n",
    "        solver=miqp_solver_to_use,\n",
    "        verbose_solver=False, # Set to True for detailed solver logs\n",
    "        verbose_script=True\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nCVXPY MIQP Solver finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Reconstruct signal s = R*x where R is s_recovered\n",
    "    # s_recovered_cvxpy already has 0s where x_recovered_cvxpy is 0 if solver worked.\n",
    "    s_reconstructed_cvxpy = s_recovered_cvxpy\n",
    "\n",
    "    print(f\"\\nTrue s:              {np.array2string(s_true, precision=3, floatmode='fixed')}\")\n",
    "    # s_recovered_cvxpy contains the actual signal values\n",
    "    print(f\"Recovered s (CVXPY): {np.array2string(s_recovered_cvxpy, precision=3, floatmode='fixed')}\")\n",
    "    print(f\"Recovered x (CVXPY): {np.array2string(x_recovered_cvxpy, precision=0, floatmode='fixed')}\")\n",
    "\n",
    "    mse_s = np.mean((s_true - s_reconstructed_cvxpy)**2)\n",
    "    mse_y = np.mean((y_measurements - A_sensing_matrix @ s_reconstructed_cvxpy)**2)\n",
    "    recovered_sparsity = np.sum(x_recovered_cvxpy > 0.5)\n",
    "\n",
    "    l0_obj_val = 0.5 * np.sum((A_sensing_matrix @ s_reconstructed_cvxpy - y_measurements)**2) + \\\n",
    "                 lambda_l0_param * recovered_sparsity\n",
    "\n",
    "    print(f\"\\nMSE (s_true vs s_reconstructed): {mse_s:.4e}\")\n",
    "    print(f\"MSE (y_true vs A@s_reconstructed): {mse_y:.4e}\")\n",
    "    print(f\"True sparsity: {sparsity_true}, Recovered sparsity: {recovered_sparsity}\")\n",
    "    print(f\"CVXPY L0 Objective Value (lambda={lambda_l0_param}): {l0_obj_val:.4e}\")\n",
    "\n",
    "    true_support = set(np.where(np.abs(s_true) > 1e-6)[0])\n",
    "    recovered_support_cvxpy = set(np.where(x_recovered_cvxpy > 0.5)[0])\n",
    "    print(f\"True support: {true_support}\")\n",
    "    print(f\"Recovered support (CVXPY): {recovered_support_cvxpy}\")\n",
    "    if true_support == recovered_support_cvxpy:\n",
    "        if np.allclose(s_true[list(true_support)], s_reconstructed_cvxpy[list(true_support)], atol=1e-3): # Check values too\n",
    "            print(\"SUCCESS: Exact support and close values recovery by CVXPY MIQP!\")\n",
    "        else:\n",
    "            print(\"SUCCESS: Exact support recovery by CVXPY MIQP (values might differ slightly).\")\n",
    "    else:\n",
    "        print(\"INFO: Support not exactly recovered by CVXPY MIQP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKZTbA3VFtQz"
   },
   "source": [
    "## Dirac-3 Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Problem Summary\n",
    "\n",
    "The goal is to solve the L0-regularized sparse recovery problem, which seeks a sparse signal `R` that best explains a measurement `y`:\n",
    "\n",
    "$$\\min_{\\sigma \\in \\{0,1\\}^N, R \\in \\mathbb{R}^N} \\left( \\frac{1}{2} \\| y - A(\\sigma \\circ R) \\|_2^2 + \\lambda \\|\\sigma\\|_0 \\right)$$\n",
    "\n",
    "To adapt this for a specialized solver that only accepts non-negative variables and a polynomial objective, we perform several transformations:\n",
    "\n",
    "1.  **Relaxation of Sparsity**: The binary sparsity-inducing variable $\\sigma_r \\in \\{0,1\\}$ is relaxed to a continuous variable $x_r \\in [0,1]$. To enforce this, a penalty term is added to encourage $x_r$ to be close to 0 or 1.\n",
    "2.  **Decomposition of `R`**: The real-valued signal $R_r$ is decomposed into two non-negative variables, $R_r = R_{+,r} - R_{-,r}$, where $R_{+,r}, R_{-,r} \\ge 0$. Two penalties are added: one to ensure their product $R_{+,r}R_{-,r}$ is near zero, and an optional second penalty to keep their values below a specified maximum, $R_{max}$.\n",
    "\n",
    "This results in the following unconstrained polynomial objective function over non-negative variables $(x, R_+, R_-)$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x, R_+, R_- \\ge 0} \\Bigg( & \\underbrace{\\frac{1}{2} \\| y - A(x \\circ (R_+ - R_-)) \\|_2^2}_{\\text{Original Objective}} + \\underbrace{\\lambda \\sum_{r=1}^N x_r}_{\\text{L0 Approx.}} \\\\\n",
    "& + \\underbrace{\\mu \\sum_{r=1}^N x_r(1-x_r)}_{\\text{Binary Penalty}} + \\underbrace{P \\sum_{r=1}^N R_{+,r}R_{-,r}}_{\\text{Exclusivity Penalty}} \\\\\n",
    "& + \\underbrace{P_{bound} \\sum_{r=1}^N \\left( R_{+,r}(R_{max} - R_{+,r}) + R_{-,r}(R_{max} - R_{-,r}) \\right)}_{\\text{Optional Bounding Penalty}} \\Bigg)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The Python script `convert_problem_to_quartic_poly` transforms this final objective into a list of coefficients and variable indices suitable for the hardware solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we add slack variables for $R^+$ and $R^-$ in order to bound them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_problem_to_quartic_poly(\n",
    "    A_matrix, y_vector, \n",
    "    lambda_penalty, mu_relax_penalty, P_positivity_penalty,\n",
    "    add_slack_for_sum_constraint=False,\n",
    "    R_max_bound=None, P_bound_penalty=0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts the L0-sparse recovery problem to a quartic polynomial objective\n",
    "    for a specialized solver that takes positive variables.\n",
    "\n",
    "    This version includes an optional quadratic penalty to bound R+ and R- variables.\n",
    "\n",
    "    Args:\n",
    "        A_matrix (np.ndarray): The M x N measurement matrix A.\n",
    "        y_vector (np.ndarray): The M x 1 measurement vector y.\n",
    "        lambda_penalty (float): Coefficient for the original L0 norm penalty.\n",
    "        mu_relax_penalty (float): Coefficient for the relaxation penalty sum_r x_r(1-x_r).\n",
    "        P_positivity_penalty (float): Coefficient for the penalty sum_r R_{+r}R_{-r}.\n",
    "        add_slack_for_sum_constraint (bool): If True, adds a slack variable to\n",
    "            nullify a mandatory sum constraint in the solver.\n",
    "        R_max_bound (float, optional): The target upper bound for R+ and R- variables.\n",
    "            If provided, P_bound_penalty must also be non-zero.\n",
    "        P_bound_penalty (float, optional): The coefficient for the bounding penalty\n",
    "            P_bound * R(R_max_bound - R). Defaults to 0.0 (no penalty).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (poly_coeffs, poly_indices, total_num_vars)\n",
    "    \"\"\"\n",
    "    A = np.asarray(A_matrix)\n",
    "    y = np.asarray(y_vector)\n",
    "\n",
    "    if A.ndim != 2 or y.ndim != 1 or A.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"Input dimensions are incorrect.\")\n",
    "\n",
    "    if P_bound_penalty != 0 and R_max_bound is None:\n",
    "        raise ValueError(\"If P_bound_penalty is set, R_max_bound must also be provided.\")\n",
    "\n",
    "    M, N = A.shape\n",
    "\n",
    "    # Determine the total number of variables for the solver\n",
    "    num_base_vars = 3 * N\n",
    "    total_num_vars = num_base_vars + 1 if add_slack_for_sum_constraint else num_base_vars\n",
    "\n",
    "    # Variable mapping (1-based indexing for solver)\n",
    "    # x_r       -> r + 1\n",
    "    # R_{+,r}   -> N + r + 1\n",
    "    # R_{-,r}   -> 2*N + r + 1\n",
    "    # S1 (slack) -> 3*N + 1\n",
    "\n",
    "    b_vec = A.T @ y\n",
    "    Q_mat = A.T @ A\n",
    "\n",
    "    term_map = {}\n",
    "    \n",
    "    def add_term_to_map(coeff, var_indices_list):\n",
    "        if coeff == 0:\n",
    "            return\n",
    "        \n",
    "        sorted_actual_indices = sorted([v_idx for v_idx in var_indices_list if v_idx != 0])\n",
    "        padded_list = [0] * 4\n",
    "        current_len = len(sorted_actual_indices)\n",
    "        for i in range(current_len):\n",
    "            padded_list[4 - 1 - i] = sorted_actual_indices[current_len - 1 - i]\n",
    "        \n",
    "        final_indices_tuple = tuple(sorted(padded_list))\n",
    "        term_map[final_indices_tuple] = term_map.get(final_indices_tuple, 0) + coeff\n",
    "\n",
    "    # --- Populate the term map ---\n",
    "    for r_idx in range(N):\n",
    "        var_x_r = r_idx + 1\n",
    "        var_R_plus_r = N + r_idx + 1\n",
    "        var_R_minus_r = 2 * N + r_idx + 1\n",
    "\n",
    "        # Original penalties\n",
    "        add_term_to_map(lambda_penalty + mu_relax_penalty, [var_x_r])\n",
    "        add_term_to_map(-mu_relax_penalty, [var_x_r, var_x_r])\n",
    "        add_term_to_map(P_positivity_penalty, [var_R_plus_r, var_R_minus_r])\n",
    "\n",
    "        # NEW: Add bounding penalties for R+ and R-\n",
    "        # The penalty is -P_bound * R(R_max - R) to encourage R to be in [0, R_max].\n",
    "        # We add P_bound * (R*R_max - R^2) to the objective.\n",
    "        if P_bound_penalty != 0 and R_max_bound is not None:\n",
    "            # Penalty for R+_r\n",
    "            add_term_to_map(P_bound_penalty * R_max_bound, [var_R_plus_r]) # Linear term\n",
    "            add_term_to_map(-P_bound_penalty, [var_R_plus_r, var_R_plus_r]) # Quadratic term\n",
    "            # Penalty for R-_r\n",
    "            add_term_to_map(P_bound_penalty * R_max_bound, [var_R_minus_r]) # Linear term\n",
    "            add_term_to_map(-P_bound_penalty, [var_R_minus_r, var_R_minus_r]) # Quadratic term\n",
    "\n",
    "        # Main objective terms\n",
    "        br_val = b_vec[r_idx]\n",
    "        if br_val != 0:\n",
    "            add_term_to_map(-br_val, [var_x_r, var_R_plus_r])\n",
    "            add_term_to_map(br_val, [var_x_r, var_R_minus_r])\n",
    "\n",
    "        for s_idx in range(N):\n",
    "            var_x_s = s_idx + 1\n",
    "            var_R_plus_s = N + s_idx + 1\n",
    "            var_R_minus_s = 2 * N + s_idx + 1\n",
    "            \n",
    "            Q_rs_val = Q_mat[r_idx, s_idx]\n",
    "            if Q_rs_val == 0: continue\n",
    "            \n",
    "            coeff_val_rs = 0.5 * Q_rs_val\n",
    "            add_term_to_map(coeff_val_rs, [var_x_r, var_R_plus_r, var_x_s, var_R_plus_s])\n",
    "            add_term_to_map(-coeff_val_rs, [var_x_r, var_R_plus_r, var_x_s, var_R_minus_s])\n",
    "            add_term_to_map(-coeff_val_rs, [var_x_r, var_R_minus_r, var_x_s, var_R_plus_s])\n",
    "            add_term_to_map(coeff_val_rs, [var_x_r, var_R_minus_r, var_x_s, var_R_minus_s])\n",
    "\n",
    "    final_poly_coeffs = []\n",
    "    final_poly_indices = []\n",
    "    for indices_tuple, summed_coeff in term_map.items():\n",
    "        if summed_coeff != 0:\n",
    "            final_poly_indices.append(list(indices_tuple))\n",
    "            final_poly_coeffs.append(summed_coeff)\n",
    "            \n",
    "    return final_poly_coeffs, final_poly_indices, total_num_vars\n",
    "\n",
    "def decode_solution(solver_solution, N, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Decodes the solution from the specialized solver back to the original\n",
    "    problem's sigma and R vectors.\n",
    "    \"\"\"\n",
    "    solution_vec = np.asarray(solver_solution)\n",
    "    if solution_vec.size < 3 * N:\n",
    "        raise ValueError(f\"solver_solution has size {solution_vec.size}, but expected at least {3*N}.\")\n",
    "\n",
    "    x_vars = solution_vec[0:N]\n",
    "    R_plus_vars = solution_vec[N:2*N]\n",
    "    R_minus_vars = solution_vec[2*N:3*N]\n",
    "\n",
    "    sigma_decoded = (x_vars >= threshold).astype(int)\n",
    "    R_decoded = R_plus_vars - R_minus_vars\n",
    "    R_decoded[sigma_decoded == 0] = 0.0\n",
    "\n",
    "    return sigma_decoded, R_decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lt4IUE3GCZB"
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4U6s3VYFytQ",
    "outputId": "eb5dbda0-6453-4b64-e58b-926a795feef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_matrix (M x N = 5 x 3):\n",
      " [[4.17022005e-01 7.20324493e-01 1.14374817e-04]\n",
      " [3.02332573e-01 1.46755891e-01 9.23385948e-02]\n",
      " [1.86260211e-01 3.45560727e-01 3.96767474e-01]\n",
      " [5.38816734e-01 4.19194514e-01 6.85219500e-01]\n",
      " [2.04452250e-01 8.78117436e-01 2.73875932e-02]]\n",
      "y_vector (M = 5):\n",
      " [0.67046751 0.4173048  0.55868983 0.14038694 0.19810149]\n",
      "lambda: 0.1, eps: 1.0, gamma: 10.0\n",
      "\n",
      "Generated Polynomial Terms:\n",
      "Number of terms: 36\n",
      "\n",
      "--- Index Formatting Test (using internal logic similar to add_term_temp) ---\n",
      "x1 ([1]): [0, 0, 0, 1]\n",
      "x1^2 ([1,1]): [0, 0, 1, 1]\n",
      "x1*x2 ([1,2]): [0, 0, 1, 2]\n",
      "x1^2*x2 ([1,1,2]): [0, 1, 1, 2]\n",
      "x1*x2*x3*x4 ([1,2,3,4]): [1, 2, 3, 4]\n",
      "Constant ([]): [0, 0, 0, 0]\n",
      "\n",
      "Detailed Polynomial Terms (small example):\n",
      "  Term 1: Coefficient = 1.1000, Indices = [0, 0, 0, 1]\n",
      "  Term 2: Coefficient = -1.0000, Indices = [0, 0, 1, 1]\n",
      "  Term 3: Coefficient = 10.0000, Indices = [0, 0, 4, 7]\n",
      "  Term 4: Coefficient = -0.6260, Indices = [0, 0, 1, 4]\n",
      "  Term 5: Coefficient = 0.6260, Indices = [0, 0, 1, 7]\n",
      "  Term 6: Coefficient = 0.3161, Indices = [1, 1, 4, 4]\n",
      "  Term 7: Coefficient = -0.6321, Indices = [1, 1, 4, 7]\n",
      "  Term 8: Coefficient = 0.3161, Indices = [1, 1, 7, 7]\n",
      "  Term 9: Coefficient = 0.8145, Indices = [1, 2, 4, 5]\n",
      "  Term 10: Coefficient = -0.8145, Indices = [1, 2, 4, 8]\n",
      "  Term 11: Coefficient = -0.8145, Indices = [1, 2, 5, 7]\n",
      "  Term 12: Coefficient = 0.8145, Indices = [1, 2, 7, 8]\n",
      "  Term 13: Coefficient = 0.4767, Indices = [1, 3, 4, 6]\n",
      "  Term 14: Coefficient = -0.4767, Indices = [1, 3, 4, 9]\n",
      "  Term 15: Coefficient = -0.4767, Indices = [1, 3, 6, 7]\n",
      "  Term 16: Coefficient = 0.4767, Indices = [1, 3, 7, 9]\n",
      "  Term 17: Coefficient = 1.1000, Indices = [0, 0, 0, 2]\n",
      "  Term 18: Coefficient = -1.0000, Indices = [0, 0, 2, 2]\n",
      "  Term 19: Coefficient = 10.0000, Indices = [0, 0, 5, 8]\n",
      "  Term 20: Coefficient = -0.9701, Indices = [0, 0, 2, 5]\n",
      "  Term 21: Coefficient = 0.9701, Indices = [0, 0, 2, 8]\n",
      "  Term 22: Coefficient = 0.8033, Indices = [2, 2, 5, 5]\n",
      "  Term 23: Coefficient = -1.6066, Indices = [2, 2, 5, 8]\n",
      "  Term 24: Coefficient = 0.8033, Indices = [2, 2, 8, 8]\n",
      "  Term 25: Coefficient = 0.4620, Indices = [2, 3, 5, 6]\n",
      "  Term 26: Coefficient = -0.4620, Indices = [2, 3, 5, 9]\n",
      "  Term 27: Coefficient = -0.4620, Indices = [2, 3, 6, 8]\n",
      "  Term 28: Coefficient = 0.4620, Indices = [2, 3, 8, 9]\n",
      "  Term 29: Coefficient = 1.1000, Indices = [0, 0, 0, 3]\n",
      "  Term 30: Coefficient = -1.0000, Indices = [0, 0, 3, 3]\n",
      "  Term 31: Coefficient = 10.0000, Indices = [0, 0, 6, 9]\n",
      "  Term 32: Coefficient = -0.3619, Indices = [0, 0, 3, 6]\n",
      "  Term 33: Coefficient = 0.3619, Indices = [0, 0, 3, 9]\n",
      "  Term 34: Coefficient = 0.3181, Indices = [3, 3, 6, 6]\n",
      "  Term 35: Coefficient = -0.6362, Indices = [3, 3, 6, 9]\n",
      "  Term 36: Coefficient = 0.3181, Indices = [3, 3, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "# Example Usage (as per the problem description structure)\n",
    "# N: number of (sigma_r, R_r) pairs\n",
    "# M: dimension of y\n",
    "\n",
    "N_vars = 3 # Number of original (sigma, R) variables\n",
    "M_meas = 5 # Number of measurements\n",
    "\n",
    "# Random example data\n",
    "np.random.seed(1)\n",
    "A_matrix = np.random.rand(M_meas, N_vars)\n",
    "y_vector = np.random.rand(M_meas)\n",
    "\n",
    "lambda_p = 0.1  # L0 penalty\n",
    "eps = 1.0     # x(1-x) penalty\n",
    "gamma = 10.0     # R+R- penalty\n",
    "\n",
    "print(f\"A_matrix (M x N = {M_meas} x {N_vars}):\\n\", A_matrix)\n",
    "print(f\"y_vector (M = {M_meas}):\\n\", y_vector)\n",
    "print(f\"lambda: {lambda_p}, eps: {eps}, gamma: {gamma}\\n\")\n",
    "\n",
    "coeffsG, indicesG = convert_problem_to_quartic_poly(A_matrix, y_vector, lambda_p, eps, gamma)\n",
    "\n",
    "print(\"Generated Polynomial Terms:\")\n",
    "print(f\"Number of terms: {len(coeffsG)}\")\n",
    "# for i in range(len(coeffs)):\n",
    "#     print(f\"Coeff: {coeffs[i]:.4f}, Indices: {indices[i]}\")\n",
    "\n",
    "# Small test case from the problem description for index formatting\n",
    "# E = 3.14 - 2*x1 + 3*x2 - 4*x1^2 + 5*x1*x2 - 6*x1*x2 + 7*x1^2*x2 - 8*x2^3\n",
    "# Assuming N=2 (for x1, x2). Max degree 3 for this example.\n",
    "# Our code is specific to the L0 problem and generates up to quartic.\n",
    "# Test the padding and sorting of indices in `add_term_temp` logic:\n",
    "\n",
    "print(\"\\n--- Index Formatting Test (using internal logic similar to add_term_temp) ---\")\n",
    "test_poly_coeffs = []\n",
    "test_poly_indices = []\n",
    "\n",
    "# Test add_term_temp's core logic for formatting:\n",
    "def test_format_indices(var_indices_list_in):\n",
    "    sorted_actual_indices = sorted([v_idx for v_idx in var_indices_list_in if v_idx != 0])\n",
    "    padded_list = [0] * 4 # Quartic\n",
    "    current_len = len(sorted_actual_indices)\n",
    "    for i in range(current_len):\n",
    "        padded_list[4 - 1 - i] = sorted_actual_indices[current_len - 1 - i]\n",
    "    return sorted(padded_list)\n",
    "\n",
    "# Test cases for formatting (assuming quartic, so length 4)\n",
    "# x1 (var index 1)\n",
    "print(f\"x1 ([1]): {test_format_indices([1])}\") # Expected: [0,0,0,1]\n",
    "# x1^2 ([1,1])\n",
    "print(f\"x1^2 ([1,1]): {test_format_indices([1,1])}\") # Expected: [0,0,1,1]\n",
    "# x1*x2 ([1,2])\n",
    "print(f\"x1*x2 ([1,2]): {test_format_indices([1,2])}\") # Expected: [0,0,1,2]\n",
    "# x1^2*x2 ([1,1,2])\n",
    "print(f\"x1^2*x2 ([1,1,2]): {test_format_indices([1,1,2])}\") # Expected: [0,1,1,2]\n",
    "# x1*x2*x3*x4 ([1,2,3,4])\n",
    "print(f\"x1*x2*x3*x4 ([1,2,3,4]): {test_format_indices([1,2,3,4])}\") # Expected: [1,2,3,4]\n",
    "# Constant term (empty list)\n",
    "print(f\"Constant ([]): {test_format_indices([])}\") # Expected: [0,0,0,0]\n",
    "\n",
    "# Example of a more complex output from the main function for a small N\n",
    "if N_vars <= 3 and M_meas <=5: # Print details for small problems\n",
    "      print(\"\\nDetailed Polynomial Terms (small example):\")\n",
    "      for i in range(len(coeffsG)):\n",
    "          print(f\"  Term {i+1}: Coefficient = {coeffsG[i]:.4f}, Indices = {indicesG[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Zrzgophywr2"
   },
   "source": [
    "## Run on Dirac-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iR_nNQKvyxo9"
   },
   "outputs": [],
   "source": [
    "import qci_client as qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "iSByUFUOzB6I",
    "outputId": "ea818b3e-311f-4cd6-b7ee-0a009ab3785f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metered': True, 'seconds': 8912, 'paid': True}\n"
     ]
    }
   ],
   "source": [
    "client = qc.QciClient()\n",
    "print(client.get_allocations()[\"allocations\"][\"dirac\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True sparse signal (s_true) [3 non-zeros]:\n",
      "[ 0.         -1.96845415  0.          0.          0.         -6.7426344\n",
      "  0.          0.         -4.16287612  0.        ]\n",
      "\n",
      "Sensing matrix A shape: (5, 10)\n",
      "Measurement vector y shape: (5,)\n"
     ]
    }
   ],
   "source": [
    "N_signal = 10\n",
    "M_measurements = 5\n",
    "sparsity_true = 3\n",
    "lambda_p = 0.2 # Lambda for the L0 objective\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Generate a true sparse signal s_true\n",
    "s_true = np.zeros(N_signal)\n",
    "non_zero_indices = np.random.choice(N_signal, sparsity_true, replace=False)\n",
    "# Make true signal values distinct and somewhat large to test Big-M\n",
    "s_true[non_zero_indices] = (np.random.randn(sparsity_true) * 3) + np.copysign(5, np.random.randn(sparsity_true))\n",
    "print(f\"True sparse signal (s_true) [{np.sum(s_true!=0)} non-zeros]:\\n{s_true}\")\n",
    "\n",
    "# 2. Generate a random sensing matrix A\n",
    "A_sensing_matrix = np.random.randn(M_measurements, N_signal)\n",
    "# A_sensing_matrix = A_sensing_matrix / np.linalg.norm(A_sensing_matrix, axis=0, keepdims=True)\n",
    "print(f\"\\nSensing matrix A shape: {A_sensing_matrix.shape}\")\n",
    "\n",
    "# 3. Compute measurements y\n",
    "y_measurements = A_sensing_matrix @ s_true\n",
    "print(f\"Measurement vector y shape: {y_measurements.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_matrix (M x N = 5 x 3):\n",
      " [[-2.61254901  0.95036968  0.81644508 -1.523876   -0.42804606 -0.74240684\n",
      "  -0.7033438  -2.13962066 -0.62947496  0.59772047]\n",
      " [ 2.55948803  0.39423302  0.12221917 -0.51543566 -0.60025385  0.94743982\n",
      "   0.291034   -0.63555974 -1.02155219 -0.16175539]\n",
      " [-0.5336488  -0.00552786 -0.22945045  0.38934891 -1.26511911  1.09199226\n",
      "   2.77831304  1.19363972  0.21863832  0.88176104]\n",
      " [-1.00908534 -1.58329421  0.77370042 -0.53814166 -1.3466781  -0.88059127\n",
      "  -1.1305523   0.13442888  0.58212279  0.88774846]\n",
      " [ 0.89433233  0.7549978  -0.20716589 -0.62347739 -1.50815329  1.09964698\n",
      "  -0.17773212 -0.41038331  1.17971634 -0.89820794]]\n",
      "y_vector (M = 5):\n",
      " [  5.75544502  -2.91167472  -8.26218749   6.63084194 -13.81170908]\n",
      "lambda: 0.1, eps: 0.5, gamma: 0.5\n",
      "\n",
      "Generated Polynomial Terms:\n",
      "Number of terms: 300\n",
      "terms: 31\n"
     ]
    }
   ],
   "source": [
    "eps = 0.5     # x(1-x) penalty\n",
    "gamma = 0.5     # R+R- penalty\n",
    "\n",
    "print(f\"A_matrix (M x N = {M_meas} x {N_vars}):\\n\", A_sensing_matrix)\n",
    "print(f\"y_vector (M = {M_meas}):\\n\", y_measurements)\n",
    "print(f\"lambda: {lambda_p}, eps: {eps}, gamma: {gamma}\\n\")\n",
    "\n",
    "coeffsG, indicesG, terms = convert_problem_to_quartic_poly(A_sensing_matrix, y_measurements, lambda_p, eps, gamma, add_slack_for_sum_constraint=True,\n",
    "    R_max_bound=7, P_bound_penalty=0.01)\n",
    "\n",
    "print(\"Generated Polynomial Terms:\")\n",
    "print(f\"Number of terms: {len(coeffsG)}\")\n",
    "print(f\"terms: {terms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "s1_pzfRlzD4P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num variables:31, max degree: 4\n",
      "num of zero in poly_indices: 210 (if nonzero, calculate min_degree)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "poly_indices = indicesG\n",
    "poly_coefficients = coeffsG\n",
    "\n",
    "ind_dict = Counter(np.array(poly_indices).flatten().tolist())\n",
    "num_vars = len(ind_dict)\n",
    "max_deg = len(poly_indices[0])\n",
    "\n",
    "print(f\"num variables:{ num_vars}, max degree: {max_deg}\")\n",
    "print(f\"num of zero in poly_indices: {ind_dict[0]} (if nonzero, calculate min_degree)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"idx\": idx, \"val\": val} for idx, val in zip(poly_indices, poly_coefficients)]\n",
    "file = {\n",
    "    \"file_name\": \"hello-world\",\n",
    "    \"file_config\": {\n",
    "        \"polynomial\": {\n",
    "            \"num_variables\": 31,\n",
    "            \"min_degree\": 1,\n",
    "            \"max_degree\": 4,\n",
    "            \"data\": data,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.upload_file(file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the job body to be submitted to the API.\n",
    "# This is where the job type and the Dirac-3 device and its configuration are specified.\n",
    "job_body = client.build_job_body(\n",
    "    job_type='sample-hamiltonian',\n",
    "    job_name='l0_run5', # user-defined string, optional\n",
    "    job_tags=['eqcintern', 'l0'],  # user-defined list of string identifiers, optional\n",
    "    job_params={'device_type': 'dirac-3', 'relaxation_schedule': 2, 'sum_constraint': 30, 'num_samples':100},\n",
    "    polynomial_file_id=file_response['file_id'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:45:52 - Dirac allocation balance = 4254 s\n",
      "2025-06-10 09:45:52 - Job submitted: job_id='68483710b8b42e8edbee8050'\n",
      "2025-06-10 09:45:52 - QUEUED\n",
      "2025-06-10 09:45:55 - RUNNING\n",
      "2025-06-10 09:59:50 - COMPLETED\n",
      "2025-06-10 09:59:53 - Dirac allocation balance = 3428 s\n"
     ]
    }
   ],
   "source": [
    "# Submit the job and await the result.\n",
    "# response = client.process_job(job_body=job_body, wait=True)\n",
    "job_response = client.process_job(job_body=job_body)\n",
    "assert job_response[\"status\"] == qc.JobStatus.COMPLETED.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('l0_run5.json', 'w') as tfile:\n",
    "    json.dump(job_response, tfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [x_1, x_2] = [0, 0, 29.6756248, 0, 7e-07, 0, 0, 0, 1e-07, 0, 0, 0, 0.3243728, 1e-07, 2.5e-06, 0, 0, 0, 0, 0, 1e-07, 0, 0, 0, 0, 0, 1e-07, 0, 2e-07, 0, 0] is suboptimal\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Result [x_1, x_2] = {job_response['results']['solutions'][0]} is \" +\n",
    "    (\"optimal\" if job_response[\"results\"][\"energies\"][0] == -1 else \"suboptimal\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_solution(solver_solution, N, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Decodes the solution from the specialized solver back to the original\n",
    "    problem's sigma and R vectors.\n",
    "\n",
    "    Args:\n",
    "        solver_solution (list or np.ndarray): The vector of variable values\n",
    "            returned by the solver. Length should be 3*N or 3*N+1.\n",
    "        N (int): The number of original (sigma, R) variable pairs.\n",
    "        threshold (float): The cutoff value (between 0 and 1) to determine\n",
    "            if a relaxed x_r variable should be considered 1 or 0.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sigma_decoded, R_decoded)\n",
    "            sigma_decoded (np.ndarray): The decoded binary vector representing the mask.\n",
    "            R_decoded (np.ndarray): The decoded real-valued signal vector.\n",
    "    \"\"\"\n",
    "    solution_vec = np.asarray(solver_solution)\n",
    "    if solution_vec.size < 3 * N:\n",
    "        raise ValueError(f\"solver_solution has size {solution_vec.size}, but expected at least {3*N}.\")\n",
    "\n",
    "    # Parse the solver's solution vector, ignoring any slack variables at the end\n",
    "    x_vars = solution_vec[0:N]\n",
    "    R_plus_vars = solution_vec[N:2*N]\n",
    "    R_minus_vars = solution_vec[2*N:3*N]\n",
    "\n",
    "    # Decode sigma by applying the threshold to the relaxed x variables\n",
    "    sigma_decoded = (x_vars >= threshold).astype(int)\n",
    "\n",
    "    # Reconstruct the real-valued R vector from its positive and negative parts\n",
    "    R_decoded = R_plus_vars - R_minus_vars\n",
    "    \n",
    "    # Enforce sparsity: where sigma is 0, R should also be 0.\n",
    "    R_decoded[sigma_decoded == 0] = 0.0\n",
    "\n",
    "    return sigma_decoded, R_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0.       , 0.       , 0.3243728, 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ]))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_solution(job_response['results']['solutions'][0], 10, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve with Gurobi, SCIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CVXPY MIQP: Estimated Big-M = 15.83\n",
      "  CVXPY MIQP: Solving with N=10, M=5, lambda=0.01, BigM=15.8\n",
      "  Using solver: SCIP\n",
      "  CVXPY MIQP: Optimization successful (Status: optimal). Objective value: 3.0000e-02\n",
      "\n",
      "CVXPY MIQP Solver finished in 0.55 seconds.\n",
      "\n",
      "True s:              [ 0.000 -1.968  0.000  0.000  0.000 -6.743  0.000  0.000 -4.163  0.000]\n",
      "Recovered s (CVXPY): [ 0.000 -1.968  0.000  0.000  0.000 -6.743  0.000  0.000 -4.163  0.000]\n",
      "Recovered x (CVXPY): [0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "\n",
      "MSE (s_true vs s_reconstructed): 1.2800e-21\n",
      "MSE (y_true vs A@s_reconstructed): 4.8558e-21\n",
      "True sparsity: 3, Recovered sparsity: 3\n",
      "CVXPY L0 Objective Value (lambda=0.01): 3.0000e-02\n",
      "True support: {8, 1, 5}\n",
      "Recovered support (CVXPY): {8, 1, 5}\n",
      "SUCCESS: Exact support and close values recovery by CVXPY MIQP!\n"
     ]
    }
   ],
   "source": [
    "# miqp_solver_to_use = cp.GUROBI # To let CVXPY choose\n",
    "miqp_solver_to_use = cp.SCIP\n",
    "\n",
    "start_time = time.time()\n",
    "s_recovered_cvxpy, x_recovered_cvxpy = solve_l0_cvxpy_miqp(\n",
    "    A_matrix=A_sensing_matrix,\n",
    "    y_vector=y_measurements,\n",
    "    lambda_val=lambda_l0_param,\n",
    "    N_signal=N_signal,\n",
    "    M_measure=M_measurements,\n",
    "    big_M_value=M_val_heuristic,\n",
    "    solver=miqp_solver_to_use,\n",
    "    verbose_solver=False, # Set to True for detailed solver logs\n",
    "    verbose_script=True\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"\\nCVXPY MIQP Solver finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Reconstruct signal s = R*x where R is s_recovered\n",
    "# s_recovered_cvxpy already has 0s where x_recovered_cvxpy is 0 if solver worked.\n",
    "s_reconstructed_cvxpy = s_recovered_cvxpy\n",
    "\n",
    "print(f\"\\nTrue s:              {np.array2string(s_true, precision=3, floatmode='fixed')}\")\n",
    "# s_recovered_cvxpy contains the actual signal values\n",
    "print(f\"Recovered s (CVXPY): {np.array2string(s_recovered_cvxpy, precision=3, floatmode='fixed')}\")\n",
    "print(f\"Recovered x (CVXPY): {np.array2string(x_recovered_cvxpy, precision=0, floatmode='fixed')}\")\n",
    "\n",
    "mse_s = np.mean((s_true - s_reconstructed_cvxpy)**2)\n",
    "mse_y = np.mean((y_measurements - A_sensing_matrix @ s_reconstructed_cvxpy)**2)\n",
    "recovered_sparsity = np.sum(x_recovered_cvxpy > 0.5)\n",
    "\n",
    "l0_obj_val = 0.5 * np.sum((A_sensing_matrix @ s_reconstructed_cvxpy - y_measurements)**2) + \\\n",
    "             lambda_l0_param * recovered_sparsity\n",
    "\n",
    "print(f\"\\nMSE (s_true vs s_reconstructed): {mse_s:.4e}\")\n",
    "print(f\"MSE (y_true vs A@s_reconstructed): {mse_y:.4e}\")\n",
    "print(f\"True sparsity: {sparsity_true}, Recovered sparsity: {recovered_sparsity}\")\n",
    "print(f\"CVXPY L0 Objective Value (lambda={lambda_l0_param}): {l0_obj_val:.4e}\")\n",
    "\n",
    "true_support = set(np.where(np.abs(s_true) > 1e-6)[0])\n",
    "recovered_support_cvxpy = set(np.where(x_recovered_cvxpy > 0.5)[0])\n",
    "print(f\"True support: {true_support}\")\n",
    "print(f\"Recovered support (CVXPY): {recovered_support_cvxpy}\")\n",
    "if true_support == recovered_support_cvxpy:\n",
    "    if np.allclose(s_true[list(true_support)], s_reconstructed_cvxpy[list(true_support)], atol=1e-3): # Check values too\n",
    "        print(\"SUCCESS: Exact support and close values recovery by CVXPY MIQP!\")\n",
    "    else:\n",
    "        print(\"SUCCESS: Exact support recovery by CVXPY MIQP (values might differ slightly).\")\n",
    "else:\n",
    "    print(\"INFO: Support not exactly recovered by CVXPY MIQP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Pursuits Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import l0core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'calculate_h_prime_relaxed', 'calculate_user_hamiltonian', 'compute_stochastic_gradient', 'grad_loss_fn_original_h', 'grad_loss_fn_single_var', 'hamiltonian_h_prime', 'hamiltonian_h_prime_single_var', 'itertools', 'jax', 'jnp', 'np', 'penalty_terms_original', 'penalty_terms_single_var', 'solve_alternating_mip', 'solve_alternating_mip_B', 'solve_alternating_relaxed_h_prime', 'solve_continuous_relaxation_original_hamiltonian', 'solve_continuous_relaxation_sgd', 'solve_continuous_relaxation_single_var', 'solve_matching_pursuit', 'solve_omp', 'solve_sigma_exact', 'total_loss_function_original_hamiltonian', 'total_loss_function_single_var', 'update_step_original_h', 'update_step_sgd', 'update_step_single_var']\n"
     ]
    }
   ],
   "source": [
    "import l0core.solvers as solvers\n",
    "print(dir(solvers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l0core.solvers import solve_alternating_mip_B, solve_matching_pursuit, solve_omp, calculate_user_hamiltonian, solve_cosamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CoSaMP with target sparsity s = 3\n",
      "CoSaMP iter 1: |res|=5.2222e+00, support=[9, 5, 4], H=0.300000\n",
      "CoSaMP iter 2: |res|=2.9678e+00, support=[5, 9, 8], H=0.300000\n",
      "CoSaMP iter 3: |res|=8.7475e-15, support=[5, 1, 8], H=0.300000\n",
      "CoSaMP converged: residual norm below threshold\n",
      "Finished CoSaMP solver\n"
     ]
    }
   ],
   "source": [
    "R_mip, sigma_mip, history_H_mip = solve_cosamp(\n",
    "    A_cs_matrix=A_sensing_matrix, \n",
    "    y_cs_vec=y_measurements, \n",
    "    lambda_mip=0.1,\n",
    "    target_sparsity=3,\n",
    "    N_signal=N_signal, \n",
    "    M_measure=M_measurements,\n",
    "    num_outer_iter=150, \n",
    "    num_R_iter=10, \n",
    "    num_sigma_iter=15, # Fewer iterations for quicker test\n",
    "    initial_R=None, \n",
    "    initial_sigma=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  [0. 1. 0. 0. 0. 1. 0. 0. 1. 1.] \n",
      " R:  [ 0.00000000e+00 -1.96845415e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -6.74263440e+00  0.00000000e+00  0.00000000e+00\n",
      " -4.16287612e+00  1.58470727e-15]\n"
     ]
    }
   ],
   "source": [
    "print('sigma: ', sigma_mip, '\\n R: ', R_mip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Orthogonal Matching Pursuit solver\n",
      "OMP iter 1: support=[0], H=0.100000\n",
      "OMP iter 2: support=[0, 6], H=0.200000\n",
      "OMP iter 3: support=[0, 6, 4], H=0.300000\n",
      "OMP iter 4: support=[0, 6, 4, 1], H=0.400000\n",
      "OMP iter 5: support=[0, 6, 4, 1, 8], H=0.500000\n",
      "OMP stop at iter 5: max|corr|=0.0000 < lambda=0.1\n",
      "Finished OMP solver\n"
     ]
    }
   ],
   "source": [
    "R_mip, sigma_mip, history_H_mip = solve_omp(\n",
    "    A_cs_matrix=A_sensing_matrix, \n",
    "    y_cs_vec=y_measurements, \n",
    "    lambda_mip=0.1,\n",
    "    N_signal=N_signal, \n",
    "    M_measure=M_measurements,\n",
    "    num_outer_iter=50, \n",
    "    num_R_iter=10, \n",
    "    num_sigma_iter=15, # Fewer iterations for quicker test\n",
    "    initial_R=None, \n",
    "    initial_sigma=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  [1. 1. 0. 0. 1. 0. 1. 0. 1. 0.] \n",
      " R:  [-2.10898243 -4.54278     0.          0.          1.4516005   0.\n",
      " -2.27923557  0.         -5.68920346  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('sigma: ', sigma_mip, '\\n R: ', R_mip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "\n",
    "def solve_omp_sklearn(A_cs_matrix,\n",
    "              y_cs_vec,\n",
    "              lambda_mip,\n",
    "              N_signal,\n",
    "              M_measure,\n",
    "              num_outer_iter=50,\n",
    "              num_R_iter=None,\n",
    "              num_sigma_iter=None,\n",
    "              initial_R=None,\n",
    "              initial_sigma=None,\n",
    "              verbose=True,\n",
    "              tol=1e-6):\n",
    "    \"\"\"\n",
    "    OMP via scikit-learn's API.\n",
    "    \n",
    "    Uses lambda_mip as the stopping tolerance on residual norm.\n",
    "    Signature matches solve_alternating_mip.\n",
    "    \n",
    "    Returns:\n",
    "      R_current, sigma_current, history_H\n",
    "    \"\"\"\n",
    "    # Instantiate scikit-learn OMP with tol = lambda_mip\n",
    "    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=3, \n",
    "                                    # tol=tol,\n",
    "                                    fit_intercept=True)\n",
    "    # Fit model\n",
    "    omp.fit(A_cs_matrix, y_cs_vec)\n",
    "    coef = omp.coef_\n",
    "    \n",
    "    # Build outputs\n",
    "    R_current     = coef\n",
    "    sigma_current = (coef != 0).astype(float)\n",
    "    \n",
    "    # Compute final Hamiltonian\n",
    "    H_final = calculate_user_hamiltonian(A_cs_matrix, y_cs_vec,\n",
    "                                         R_current, sigma_current,\n",
    "                                         lambda_mip)\n",
    "    history_H = [H_final]\n",
    "    \n",
    "    if verbose:\n",
    "        sparsity = int(sigma_current.sum())\n",
    "        print(f\"scikit-learn OMP finished: sparsity = {sparsity}, H = {H_final:.6f}\")\n",
    "    \n",
    "    return R_current, sigma_current, history_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn OMP finished: sparsity = 3, H = -5.386960\n"
     ]
    }
   ],
   "source": [
    "R_mip, sigma_mip, history_H_mip = solve_omp_sklearn(\n",
    "    A_cs_matrix=A_sensing_matrix, \n",
    "    y_cs_vec=y_measurements, \n",
    "    lambda_mip=0.1,\n",
    "    N_signal=N_signal, \n",
    "    M_measure=M_measurements,\n",
    "    num_outer_iter=50, \n",
    "    num_R_iter=10, \n",
    "    num_sigma_iter=15, # Fewer iterations for quicker test\n",
    "    initial_R=None, \n",
    "    initial_sigma=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:  [1. 0. 0. 0. 0. 0. 1. 0. 1. 0.] \n",
      " R:  [-2.31221237  0.          0.          0.          0.          0.\n",
      " -2.76932826  0.         -4.97251688  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('sigma: ', sigma_mip, '\\n R: ', R_mip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
